{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Insert a project token and run the inserted code cell\n",
    "<br/>A project token will allow you to access all the resources defined within this project.  By default, the token is inserted into the very first cell in a notebook.\n",
    "<br/><img style=\"float: left;\" src=\"https://github.com/yfphoon/dsx_local/blob/master/images/project_token.png?raw=true\" alt=\"Project Token\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Attrition Demo</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "<img src=\"https://github.com/CatherineCao2016/pics/raw/master/header.png\" width=\"800\" height=\"500\" align=\"middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Attrition demo focuses on retaining Merchants that are using company network for credit card processing. Here is the description of the case:\n",
    "\n",
    "A client approved many low value merchant accounts without much scrutiny.  Many of those merchant accounts resulted in default. The client thinks that they should have put more of an emphasis on their applicant screening process. IBM suggests to enable fact based decision making for performance of its joint marketing programs.\n",
    "\n",
    "This notebook will demostrate how to\n",
    "\n",
    "1. Use Brunel and Seanborn library for visualizations\n",
    "\n",
    "2. Use regular python Machine Learning libary scikit-learn and Spark's Machine Learning library(MLlib) for predicitive modeling in an intergrated environment on DSX.\n",
    "3. Deploy SparkML model using Machine Learning Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import brunel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import chi2_contingency,ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import urllib3, requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Customer History Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data into DSX environment using Object Storage, you need to:\n",
    "\n",
    "1. Download the customer history data(CUST_HISTORY.csv) <a href=\"https://github.com/CatherineCao2016/AttritionDemo\">here</a>.\n",
    "2. Upload it into Object Storage by clicking the \"1001\" icon on the top right side -> Files -> Drag and drop or browse to select and upload the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Access 'CUST_HISTORY.csv' data file from the project.\n",
    "cust_spark = ProjectUtil.load_dataframe_from_file(pc, \"CUST_HISTORY.csv\")\n",
    "cust_spark.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame from the Spark DataFrame.  A Pandas DataFrame is required for the analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_pd=cust_spark.toPandas()\n",
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"There are \" + str(len(cust_pd)) + \" observations in the customer history dataset.\"\n",
    "print \"There are \" + str(len(cust_pd.columns)) + \" variables in the dataset.\"\n",
    "\n",
    "print \"\\n******************Descriptive statistics*****************************\\n\"\n",
    "print cust_pd.describe()\n",
    "\n",
    "print \"\\n******************Dataset Quick View*****************************\\n\"\n",
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this section, we will explore the dataset further with some visualizations.\n",
    "\n",
    "Two open source libraries are used:\n",
    "* <a href=\"https://github.com/Brunel-Visualization/Brunel\">Brunel</a> is a high-level language that describes visualizations in terms of composable actions. It drives a visualization engine (D3) that performs the actual rendering and interactivity. Brunel makes it much easier to build fun and inventive visualizations in Jupyter notebooks.\n",
    "\n",
    "* <a href=\"https://github.com/Brunel-Visualization/Brunel\">Seaborn</a> is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome Variable: Account Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') x(IS_DEFAULT) y(#count) color(IS_DEFAULT) bar tooltip(#all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the bar chart, 300 out of 1000 accounts are in default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default by Credit Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') polar stack bar y(#count) color(CREDIT_PROGRAM) percent(#count) tooltip(#all) | stack bar x(CREDIT_PROGRAM) y(#count) color(IS_DEFAULT) bin(CREDIT_PROGRAM) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Top 3 credit programs with most Merchants are Electronics(28%), New Car(23.4%) and Furniture(18.1%).\n",
    "* Top 3 credit programs with high default rate are Education(44%), New Car(38%), and Retraining(35.1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default by IS_XBORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') polar stack bar y(#count) color(IS_XBORDER) percent(#count) tooltip(#all) | stack bar x(IS_XBORDER) y(#count) color(IS_DEFAULT) bin(IS_XBORDER) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Merchants have cross-border transactions. Relatively, they have a lower default rate than those don't have coross-border transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RENT vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') stack bar x(RENT) y(#count) color(IS_DEFAULT: blue-red) bin(RENT) sort(RENT) percent(#count) label(#count) tooltip(#all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this stacked bar chart, we can see that Merchants who rent their residence have higher default rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HISTORY vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') bar x(HISTORY) y(#count) color(HISTORY) tooltip(#all) | stack bar x(HISTORY) y(#count) color(IS_DEFAULT: green-red) bin(HISTORY) sort(HISTORY) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMOUNT_K_USD vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_yes = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"Yes\"]\n",
    "sub_no = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"No\"]\n",
    "    \n",
    "p_value = ttest_ind(sub_yes['AMOUNT_K_USD'], sub_no[\"AMOUNT_K_USD\"], equal_var = False)[1]\n",
    "\n",
    "fig, axs = plt.subplots(nrows= 1, figsize=(13, 5))\n",
    "sns.boxplot(x = \"IS_DEFAULT\", y = \"AMOUNT_K_USD\", data = cust_pd, showfliers=False, palette=\"Set2\")\n",
    "if p_value < .05:\n",
    "    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n The distributions for the two groups are significantly different!\" + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_no[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))\n",
    "else:\n",
    "    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_safe[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this box plot, the visualization is enhanced by T-test statistics. The result is significant which indicates that the average credit amount for the non-default group and default group are different. Default group has larger average credit amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default rate by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_rate = pd.crosstab(cust_pd.IS_DEFAULT, cust_pd.STATE).apply(lambda r: r/r.sum(), axis=0)\n",
    "\n",
    "default_rate2 = default_rate.T\n",
    "\n",
    "%brunel data('default_rate2') map color(Yes) key(STATE) label(STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brunel also provides a very neat way for map visualization. So for this use case, all the Merchants come from 4 states: NY, NJ, PA and CT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "\n",
    "A heatmap is used to visualize the correlations between all continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "corr_df = cust_pd.iloc[:,1:].corr()\n",
    "\n",
    "sns.heatmap(corr_df, \n",
    "            xticklabels = corr_df.columns.values,\n",
    "            yticklabels = corr_df.columns.values,\n",
    "            annot = True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is no strong correlation between most variables.\n",
    "* The correlation between AMOUNT_K_USD and CONTRACT_DURATION_MONTH is moderate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling And Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purpose, we will use RandomForestClassifier() from sklearn to rank feature importance, and Logistic Regression from Spark's Machine Learning Library(MLlib) for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Random Forest: Rank Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert IS_DEFAULT to 1/0\n",
    "le = LabelEncoder()\n",
    "\n",
    "cust_pd.loc[:,'IS_DEFAULT']= le.fit_transform(cust_pd.loc[:,'IS_DEFAULT'])\n",
    "\n",
    "y = np.float32(cust_pd.IS_DEFAULT)\n",
    "X = cust_pd.copy()\n",
    "\n",
    "# drop y \n",
    "X = cust_pd.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1)\n",
    "\n",
    "# Prepocess the data: Encode categorical variables into numeric representations\n",
    "\n",
    "categoricalColumns = [\"ACCT_STATUS_K_USD\", \"BRANCHES\",'HISTORY', 'CREDIT_PROGRAM', 'ACCOUNT_TYPE', 'ACCT_AGE', 'STATE', 'IS_URBAN', 'IS_XBORDER','SELF_REPORTED_ASMT', 'CO_APPLICANT', 'GUARANTOR','PRESENT_RESIDENT', 'OWN_REAL_ESTATE', 'PROP_UNKN','OTHER_INSTALL_PLAN', 'RENT', 'OWN_RESIDENCE','TELEPHONE', 'SHIP_INTERNATIONAL']\n",
    "\n",
    "for col in categoricalColumns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# scale X\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# split the data to training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "#Stratify split and train on 5 folds\n",
    "skf = StratifiedKFold(y_train, n_folds=5)\n",
    "counter = 1\n",
    "for train_fold, test_fold in skf:\n",
    "    random_forest.fit(X_train[train_fold], y_train[train_fold])\n",
    "    \n",
    "    print( str(counter) + \": \", random_forest.score(X_train[test_fold], y_train[test_fold]))\n",
    "    counter += 1 \n",
    "    \n",
    "#### local notes: one interesting error here, if you don't do the import correctly, it will show error Params must be either a param map or a list/tuple of param maps, but got <class 'pandas.core.series.Series'>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of 5-fold CV, the average accuracy varies. The model is not very stable, one possible reason is that our sample size is really small. We will need to restrict the model complexity. We will choose top 10 important features for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_order = cust_pd.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1).columns.tolist()\n",
    "\n",
    "feature_importance_dict = {key: val for key, val in zip(features_order, random_forest.feature_importances_)}\n",
    "\n",
    "for k in sorted(feature_importance_dict, key=feature_importance_dict.get, reverse=True):\n",
    "    print k, feature_importance_dict[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Prediction: Spark MLlib Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, We will use Logistic Regression from Spark MLlib to predict defalut.<br/>\n",
    "We will use the Spark DataFrame for building the Spark ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group top 10 features to categorical and numerical\n",
    "allCols = cust_pd.drop(['MERCHANT','IS_DEFAULT'], 1).columns.tolist()\n",
    "importantCols = ['AMOUNT_K_USD', 'ACCT_STATUS_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH', 'HISTORY', 'CREDIT_PROGRAM', 'ACCT_AGE', 'ACCOUNT_TYPE', \"PRESENT_RESIDENT\", \"STATE\"]\n",
    "importantCols_num = ['AMOUNT_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH']\n",
    "importantCols_cat = np.setdiff1d(importantCols, importantCols_num).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create label_str column\n",
    "cust_spark = cust_spark.withColumnRenamed(\"IS_DEFAULT\", 'label_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoder for all categorical varaibles\n",
    "for categoricalCol in importantCols_cat:\n",
    "    cust_spark = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\").fit(cust_spark).transform(cust_spark)\n",
    "    cust_spark = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\").transform(cust_spark)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assemble feature vector\n",
    "assemblerInputs = map(lambda c: c + \"classVec\", importantCols_cat) + importantCols_num\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "cust_spark = assembler.transform(cust_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the label_str column to a numeric value\n",
    "cust_spark = StringIndexer(inputCol='label_str', outputCol='label').fit(cust_spark).transform(cust_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep useful variables\n",
    "selectedcols = [\"label\", \"features\"]\n",
    "cust_model = cust_spark.select(selectedcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split the data into training and testing sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData, testData = cust_model.randomSplit([0.7, 0.3], seed = 824)\n",
    "print trainingData.count()\n",
    "print testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use CrossValidator and ParamGridBuilder to search for best model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [1.0,0.3,0.1, 0.03,0.01,0.0]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use BinaryClassificationEvaluator to evaluate the model**\n",
    "\n",
    "Note that the default metric for the BinaryClassificationEvaluator is *areaUnderROC*\n",
    "\n",
    "A rough guide for classifying the accuracy of a test:\n",
    "\n",
    "    .90-1 = excellent (A)\n",
    "    .80-.90 = good (B)\n",
    "    .70-.80 = fair (C)\n",
    "    .60-.70 = poor (D)\n",
    "    .50-.60 = fail (F)\n",
    "\n",
    "So the model performance is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate(cvModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Final Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will move forward with the model with Top 10 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters used in final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cvModel.bestModel._java_obj.getRegParam()\n",
    "print cvModel.bestModel._java_obj.getMaxIter()\n",
    "print cvModel.bestModel._java_obj.getElasticNetParam()\n",
    "print cvModel.bestModel._java_obj.getThreshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Intercept and Weights **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Model Intercept = \" + str(cvModel.bestModel.intercept)\n",
    "\n",
    "coefficients = cvModel.bestModel.coefficients\n",
    "coefficients = map(lambda w: (float(w),), coefficients)\n",
    "weightsDF = sqlContext.createDataFrame(coefficients, [\"Feature Weight\"])\n",
    "weightsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_spark1 = sqlContext.createDataFrame(cust_pd).withColumnRenamed(\"IS_DEFAULT\", 'label')\n",
    "\n",
    "trainingData3, testData3 = cust_spark1.randomSplit([0.7, 0.3], seed = 824)\n",
    "\n",
    "SI1 = StringIndexer(inputCol='ACCOUNT_TYPE', outputCol='ACCOUNT_TYPE'+\"Index\")\n",
    "SI2 = StringIndexer(inputCol='ACCT_AGE', outputCol='ACCT_AGE'+\"Index\")\n",
    "SI3 = StringIndexer(inputCol='ACCT_STATUS_K_USD', outputCol='ACCT_STATUS_K_USD'+\"Index\")\n",
    "SI4 = StringIndexer(inputCol='CREDIT_PROGRAM', outputCol='CREDIT_PROGRAM'+\"Index\")\n",
    "SI5 = StringIndexer(inputCol='HISTORY', outputCol='HISTORY'+\"Index\")\n",
    "SI6 = StringIndexer(inputCol='PRESENT_RESIDENT', outputCol='PRESENT_RESIDENT'+\"Index\")\n",
    "SI7 = StringIndexer(inputCol='STATE', outputCol='STATE'+\"Index\")\n",
    "\n",
    "\n",
    "OH1 = OneHotEncoder(inputCol='ACCOUNT_TYPE'+\"Index\", outputCol='ACCOUNT_TYPE'+\"classVec\")\n",
    "OH2 = OneHotEncoder(inputCol='ACCT_AGE'+\"Index\", outputCol='ACCT_AGE'+\"classVec\")\n",
    "OH3 = OneHotEncoder(inputCol='ACCT_STATUS_K_USD'+\"Index\", outputCol='ACCT_STATUS_K_USD'+\"classVec\")\n",
    "OH4 = OneHotEncoder(inputCol='CREDIT_PROGRAM'+\"Index\", outputCol='CREDIT_PROGRAM'+\"classVec\")\n",
    "OH5 = OneHotEncoder(inputCol='HISTORY'+\"Index\", outputCol='HISTORY'+\"classVec\")\n",
    "OH6 = OneHotEncoder(inputCol='PRESENT_RESIDENT'+\"Index\", outputCol='PRESENT_RESIDENT'+\"classVec\")\n",
    "OH7 = OneHotEncoder(inputCol='STATE'+\"Index\", outputCol='STATE'+\"classVec\")\n",
    "\n",
    "assembler_features = VectorAssembler(inputCols=['ACCOUNT_TYPEclassVec','ACCT_AGEclassVec','ACCT_STATUS_K_USDclassVec','CREDIT_PROGRAMclassVec','HISTORYclassVec','PRESENT_RESIDENTclassVec', 'STATEclassVec',\n",
    " 'AMOUNT_K_USD',\n",
    " 'CONTRACT_DURATION_MONTH',\n",
    " 'ESTABLISHED_MONTH'], outputCol=\"features\")\n",
    "\n",
    "lr_final = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.0, threshold = 0.5, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[SI1, SI2, SI3,SI4,SI5,SI6,SI7, OH1,OH2,OH3,OH4,OH5,OH6,OH7, assembler_features, lr_final])\n",
    "model_lr = pipeline_lr.fit(trainingData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model in ML repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from repository.mlrepositoryclient import MLRepositoryClient\n",
    "from repository.mlrepositoryartifact import MLRepositoryArtifact\n",
    "\n",
    "service_path = 'https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443'\n",
    "ml_repository_client = MLRepositoryClient()\n",
    "\n",
    "model_artifact = MLRepositoryArtifact(model_lr, training_data=trainingData3, name=\"Predict_CC_Default\")\n",
    "\n",
    "saved_model = ml_repository_client.models.save(model_artifact)\n",
    "\n",
    "# Print the saved model properties\n",
    "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\n",
    "print \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\n",
    "print \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\n",
    "print \"label: \" + saved_model.meta.prop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Deploy model via UI\n",
    "\n",
    "Save the notebook and switch to the Analytic Assets tab of the project (hint: open with another tab in your browser).\n",
    "Under Models, find and click into your deployed model. Add an Online deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, you \n",
    "\n",
    "* used Brunel and Seaborn library for data visualizations\n",
    "* used regular python Machine Learning libary scikit-learn and Spark's Machine Learning library(MLlib) for predicitive modeling\n",
    "\n",
    "This notebook has been developed by Catherine Cao (Catherine.Cao@ibm.com). Some of the code was contributed by Dustin Vanstee(vanstee@us.ibm.com) and Sidney Phoon(yfphoon@us.ibm.com)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 with DSX Spark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
